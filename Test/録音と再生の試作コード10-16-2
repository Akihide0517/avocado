//
//  AudioController.swift
//  audioavocado -Test
//
//  Created by 吉田成秀 on 2023/10/16.

import Foundation
import AVFoundation
import UIKit
import Dispatch

class AudioController:  UIViewController, AVAudioRecorderDelegate, AVAudioPlayerDelegate{
    var audioRecorder: AVAudioRecorder!
    var audioPlayer: AVAudioPlayer!
    var isRecording = false
    
    @IBOutlet weak var ReverseWaveText: UITextView!
    @IBOutlet weak var WaveText: UITextView!//デバック用のm4a出力確認text
    
    override func viewDidLoad() {
        super.viewDidLoad()
        setupAudioSession()
    }
    
    @IBAction func playMusicButtonAction(_ sender: Any) {
        if AVAudioSession.sharedInstance().recordPermission == .undetermined {
            // マイクへのアクセス許可がまだリクエストされていない場合
            AVAudioSession.sharedInstance().requestRecordPermission { granted in
                if granted {
                    // マイクへのアクセスが許可された場合の処理
                    self.startRecording()
                    self.playMusicFile()
                    
                    let delayInSeconds: Double = 5.0
                    let delayQueue = DispatchQueue.global(qos: .userInitiated)

                    delayQueue.asyncAfter(deadline: .now() + delayInSeconds) {
                        // 5秒後に実行したいコードをここに書きます
                        print("5秒後に実行されました")
                        self.dilayStopMusic()
                    }
                } else {
                    // マイクへのアクセスが拒否された場合の処理
                }
            }
        } else {
            // すでにマイクへのアクセス許可が得られている場合
            self.startRecording()
            self.playMusicFile()
            
            let delayInSeconds: Double = 5.0
            let delayQueue = DispatchQueue.global(qos: .userInitiated)

            delayQueue.asyncAfter(deadline: .now() + delayInSeconds) {
                // 5秒後に実行したいコードをここに書きます
                print("5秒後に実行されました")
                self.dilayStopMusic()
            }
        }
    }
    
    @IBAction func makeWavegraphButtonAction(_ sender: Any) {
        // 波形データを取得して表示
        if let waveform = getWaveformFromAudioFile() {
            let reversedData = reverseCGFloatArray(waveform)
            print("waveform:\(waveform)")
            print("reversedData:\(reversedData)")
            
            WaveText.text = "\(waveform)"//デバック用のm4a出力確認text
            ReverseWaveText.text = "\(reversedData)"
            
            let waveformView = WaveformView()
            waveformView.frame = CGRect(x: 0, y: 0, width: 320, height: 200)
            self.view.addSubview(waveformView)
            waveformView.waveform = waveform
        } else {
            print("Failed to retrieve waveform data")
        }
        reverseAndSaveAudio()
    }
    
    @IBAction func copyButtonTapped() {
        // クリップボードにテキストをコピー
        UIPasteboard.general.string = WaveText.text
        
        // コピー完了をユーザに知らせるためにアラートを表示
        let alert = UIAlertController(title: "コピー完了", message: "WaveTextがクリップボードにコピーされました", preferredStyle: .alert)
        alert.addAction(UIAlertAction(title: "OK", style: .default, handler: nil))
        present(alert, animated: true, completion: nil)
    }
    
    @IBAction func copyButtonTapped2() {
        // クリップボードにテキストをコピー
        UIPasteboard.general.string = ReverseWaveText.text
        
        // コピー完了をユーザに知らせるためにアラートを表示
        let alert = UIAlertController(title: "コピー完了", message: "ReverseWaveTextがクリップボードにコピーされました", preferredStyle: .alert)
        alert.addAction(UIAlertAction(title: "OK", style: .default, handler: nil))
        present(alert, animated: true, completion: nil)
    }
    
    @IBAction func startPlaybackButtonAction(_ sender: Any) {
        startPlayback()
    }
    
    func dilayStopMusic(){
        stopRecording()
        stopPlayback()
        stopMusicFile()
    }
    
    func setupAudioSession() {
        do {
            let session = AVAudioSession.sharedInstance()
            try session.setCategory(.playAndRecord, mode: .default)
            try session.setActive(true)
        } catch {
            print("Failed to set up audio session: \(error)")
        }
    }
    
    func startRecording() {
        if !isRecording {
            let audioSettings = [
                AVFormatIDKey: Int(kAudioFormatMPEG4AAC),
                AVSampleRateKey: 48000.0,
                AVNumberOfChannelsKey: 2,
                AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
            ] as [String: Any]

            do {
                let audioSession = AVAudioSession.sharedInstance()
                try audioSession.setCategory(.playAndRecord, mode: .default, options: [.defaultToSpeaker, .allowBluetooth])
                try audioSession.setActive(true, options: .notifyOthersOnDeactivation)
            } catch {
                print("Failed to set up audio session: \(error)")
            }

            do {
                audioRecorder = try AVAudioRecorder(url: getDocumentsDirectory().appendingPathComponent("recording.m4a"), settings: audioSettings)
                audioRecorder.delegate = self
                audioRecorder.prepareToRecord()
                audioRecorder.record()
                isRecording = true
            } catch {
                print("Failed to set up audio recorder: \(error)")
            }
        }
    }
    
    func reverseAndSaveAudio() {
        //逆再生したいなー
    }
    
    func stopRecording() {
        if isRecording {
            audioRecorder.stop()
            isRecording = false
        }
    }
    
    func startPlayback() {
        do {
            audioPlayer = try AVAudioPlayer(contentsOf: getDocumentsDirectory().appendingPathComponent("recording.m4a"))
            audioPlayer.delegate = self
            audioPlayer.play()
        } catch {
            print("Failed to set up audio player: \(error)")
        }
    }
    
    func stopPlayback() {
        do {
            audioPlayer = try AVAudioPlayer(contentsOf: getDocumentsDirectory().appendingPathComponent("recording.m4a"))
            audioPlayer.delegate = self
            audioPlayer.stop()
        } catch {
            print("Failed to set up audio player: \(error)")
        }
    }
    
    func playMusicFile() {
        guard let url = Bundle.main.url(forResource: "sweep_sound", withExtension: "wav") else { return }
        do {
            audioPlayer = try AVAudioPlayer(contentsOf: url)
            audioPlayer.delegate = self
            audioPlayer.play()
        } catch {
            print("Failed to set up audio player: \(error)")
        }
    }
    
    func stopMusicFile() {
        guard let url = Bundle.main.url(forResource: "10", withExtension: "mp3") else { return }
        do {
            audioPlayer = try AVAudioPlayer(contentsOf: url)
            audioPlayer.delegate = self
            audioPlayer.stop()
        } catch {
            print("Failed to set up audio player: \(error)")
        }
    }

    func getDocumentsDirectory() -> URL {
        let paths = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)
        return paths[0]
    }

    func getWaveformFromAudioFile() -> [CGFloat]? {
        let audioFileURL = getDocumentsDirectory().appendingPathComponent("recording.m4a")

        if FileManager.default.fileExists(atPath: audioFileURL.path) {
            // ファイルが存在する場合の処理
            do {
                let audioFile = try AVAudioFile(forReading: audioFileURL)
                
                // 以下のコードを続けて波形データを取得する
            } catch {
                print("Failed to open audio file: \(error)")
            }
        } else {
            print("Audio file not found")
        }

        
        do {
            let audioFile = try AVAudioFile(forReading: audioFileURL)
            
            // サンプル数を取得
            let totalSamples = audioFile.length
            
            // 波形データを取得
            let format = audioFile.processingFormat
            let buffer = AVAudioPCMBuffer(pcmFormat: format, frameCapacity: AVAudioFrameCount(totalSamples))
            
            try audioFile.read(into: buffer!)
            
            // データを [CGFloat] に変換
            let floatArray = Array(UnsafeBufferPointer(start: buffer?.floatChannelData![0], count: Int(buffer!.frameLength)))
            
            let cgFloatArray = floatArray.map { CGFloat($0) }
            
            return cgFloatArray
        } catch {
            print("Failed to get waveform data: \(error)")
            return nil
        }
    }
    
    func reverseCGFloatArray(_ inputArray: [CGFloat]) -> [CGFloat] {
        let reversedArray = inputArray.reversed()
        return Array(reversedArray)
    }

}

//waveグラフ化
class WaveformView: UIView {
    var waveform: [CGFloat] = [] // 波形データを保持するプロパティ（振幅と時間の積分）

    override func draw(_ rect: CGRect) {
        super.draw(rect)

        guard let context = UIGraphicsGetCurrentContext() else { return }

        context.setFillColor(UIColor.white.cgColor)
        context.fill(rect)

        context.setStrokeColor(UIColor.blue.cgColor)
        context.setLineWidth(2.0)

        let path = UIBezierPath()

        let width = rect.size.width
        let height = rect.size.height

        for (index, amplitude) in waveform.enumerated() {
            let x = CGFloat(index) / CGFloat(waveform.count) * width
            let y = (1 - amplitude) * height
            if index == 0 {
                path.move(to: CGPoint(x: x, y: y))
            } else {
                path.addLine(to: CGPoint(x: x, y: y))
            }
        }

        context.addPath(path.cgPath)
        context.strokePath()
    }
}
