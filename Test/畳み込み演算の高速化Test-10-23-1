<!-- 超高速化仕様(GPU) -->

import Metal
import MetalKit

func convolution(_ signal1: [CGFloat], _ signal2: [CGFloat]) -> [CGFloat] {
        // Metalデバイスの初期化
        guard let device = MTLCreateSystemDefaultDevice() else {
            fatalError("Metal is not supported on this device.")
        }

        // Metalコマンドキューの作成
        let commandQueue = device.makeCommandQueue()

        // シグナルデータ (CGFloatからFloatに変換)
        let signal1: [Float] = signal1.map { Float($0) }
        let signal2: [Float] = signal2.map { Float($0) }

        // シグナルデータをMetalバッファに転送
        let signal1Buffer = device.makeBuffer(bytes: signal1, length: signal1.count * MemoryLayout<Float>.stride, options: [])
        let signal2Buffer = device.makeBuffer(bytes: signal2, length: signal2.count * MemoryLayout<Float>.stride, options: [])

        // 出力用のバッファを作成
        let outputLength = signal1.count + signal2.count - 1
        let resultBuffer = device.makeBuffer(length: outputLength * MemoryLayout<Float>.stride, options: [])

        // カスタムMetalシェーダーを記述
        let shaderSource = """
        #include <metal_stdlib>
        using namespace metal;

        kernel void convolutionKernel(device float* signal1 [[ buffer(0) ]],
                                     device float* signal2 [[ buffer(1) ]],
                                     device float* result [[ buffer(2) ]],
                                     uint gid [[ thread_position_in_grid ]]) {
            int m = signal1->get_length();
            int n = signal2->get_length();
            int outputLength = m + n - 1;

            float4 simdResult = float4(0.0, 0.0, 0.0, 0.0);

            for (int j = 0; j < m; ++j) {
                int idx = int(gid) - j;
                if (idx >= 0 && idx < n) {
                    float4 signal1Value = float4(signal1[j]);
                    float4 signal2Value = float4(signal2[idx]);
                    simdResult += signal1Value * signal2Value;
                }
            }

            result[int(gid)] = simdResult.x + simdResult.y + simdResult.z + simdResult.w;
        }
        """

        // Metalライブラリを作成
        let library = try! device.makeLibrary(source: shaderSource, options: nil)
        let kernelFunction = (library.makeFunction(name: "convolutionKernel"))!
        let pipelineState = try! device.makeComputePipelineState(function: kernelFunction)

        // コマンドバッファとエンコーダーの作成
        let commandBuffer = commandQueue!.makeCommandBuffer()
        let computeEncoder = commandBuffer!.makeComputeCommandEncoder()

        // シェーダーの設定
        computeEncoder!.setComputePipelineState(pipelineState)
        computeEncoder!.setBuffer(signal1Buffer, offset: 0, index: 0)
        computeEncoder!.setBuffer(signal2Buffer, offset: 0, index: 1)
        computeEncoder!.setBuffer(resultBuffer, offset: 0, index: 2)

        // スレッドグループとスレッド数の設定
        let threadsPerThreadgroup = MTLSize(width: 256, height: 1, depth: 1)
        let threadgroupsPerGrid = MTLSize(width: (outputLength + threadsPerThreadgroup.width - 1) / threadsPerThreadgroup.width, height: 1, depth: 1)

        // シェーダーの実行
        computeEncoder!.dispatchThreadgroups(threadgroupsPerGrid, threadsPerThreadgroup: threadsPerThreadgroup)
        computeEncoder!.endEncoding()

        // コマンドバッファの実行
        commandBuffer!.commit()
        commandBuffer!.waitUntilCompleted()

        // 結果の取得 (FloatからCGFloatに変換)
        var outputData = [CGFloat](repeating: 0, count: outputLength)
        var outputFloatData = [Float](repeating: 0, count: outputLength)
        memcpy(&outputFloatData, resultBuffer!.contents(), outputLength * MemoryLayout<Float>.stride)
        outputData = outputFloatData.map { CGFloat($0) }
        
        return outputData
    }

<!-- 超高速化仕様（精度犠牲） -->
import Dispatch
import simd

func convolution(_ signal1: [CGFloat], _ signal2: [CGFloat]) -> [CGFloat] {
        let m = signal1.count
        let n = signal2.count
        let outputLength = m + n - 1

        var result = [CGFloat](repeating: 0, count: outputLength)

        let concurrentQueue = DispatchQueue(label: "convolutionQueue", attributes: .concurrent)
        
        DispatchQueue.concurrentPerform(iterations: outputLength) { i in
            var simdResult = float4(0.0, 0.0, 0.0, 0.0) // Use SIMD float4 for vectorized operations
            for j in 0..<m {
                if i - j >= 0 && i - j < n {
                    let signal1Value = float4(Float(signal1[j]))
                    let signal2Value = float4(Float(signal2[i - j]))
                    simdResult += signal1Value * signal2Value
                }
                print("simdResult_End_\(j)")
            }
            print("simdResult_All_End")
            
            // Apply pruning by comparing each element to the threshold
            let threshold: Float = 0.001
            for index in 0..<4 {
                if simdResult[index] < threshold {
                    simdResult[index] = 0.0
                }
                print("simdResult[index]_End_\(index)")
            }
            print("simdResult[index]_All_End")
            
            // Apply quantization to reduce precision
            let quantizationFactor: Float = 0.1
            simdResult = round(simdResult / quantizationFactor) * quantizationFactor
            
            concurrentQueue.async(flags: .barrier) {
                result[i] = CGFloat(simdResult.x + simdResult.y + simdResult.z + simdResult.w)
            }
        }

        return result
    }

<!-- 高速化仕様(謎機能) -->
import Dispatch
import simd

func parallelConvolutionWithSIMD(_ signal1: [CGFloat], _ signal2: [CGFloat]) -> [CGFloat] {
    let m = signal1.count
    let n = signal2.count
    let outputLength = m + n - 1

    var result = [CGFloat](repeating: 0, count: outputLength)

    let concurrentQueue = DispatchQueue(label: "convolutionQueue", attributes: .concurrent)
    
    DispatchQueue.concurrentPerform(iterations: outputLength) { i in
        var simdResult = float4(0.0, 0.0, 0.0, 0.0) // Use SIMD float4 for vectorized operations
        for j in 0..<m {
            if i - j >= 0 && i - j < n {
                let signal1Value = float4(Float(signal1[j]))
                let signal2Value = float4(Float(signal2[i - j]))
                simdResult += signal1Value * signal2Value
            }
        }
        concurrentQueue.async(flags: .barrier) {
            result[i] = CGFloat(simdResult.x + simdResult.y + simdResult.z + simdResult.w)
        }
    }

    return result
}

<!-- 高速化仕様(マルチスレッド) -->
import Dispatch

func parallelConvolution(_ signal1: [CGFloat], _ signal2: [CGFloat]) -> [CGFloat] {
    let m = signal1.count
    let n = signal2.count
    let outputLength = m + n - 1

    var result = [CGFloat](repeating: 0, count: outputLength)

    let concurrentQueue = DispatchQueue(label: "convolutionQueue", attributes: .concurrent)
    
    DispatchQueue.concurrentPerform(iterations: outputLength) { i in
        for j in 0..<m {
            if i - j >= 0 && i - j < n {
                let product = signal1[j] * signal2[i - j]
                concurrentQueue.async(flags: .barrier) {
                    result[i] += product
                }
            }
        }
    }

    return result
}

<超高速化(マルチスレッド＋aimd)>
func convolution(_ signal1: [CGFloat], _ signal2: [CGFloat]) -> [CGFloat] {
        let m = signal1.count
        let n = signal2.count
        let outputLength = m + n - 1

        var result = [CGFloat](repeating: 0, count: outputLength)

        let concurrentQueue = DispatchQueue(label: "convolutionQueue", attributes: .concurrent)

        // SIMD を使用してベクトル化された操作を実行する
        let simdThreshold = float4(Float(0.001))
        let simdQuantizationFactor = float4(Float(0.1))

        // より効率的な convolution アルゴリズムを使用する
        // 例えば、GPU を使用している場合は、GPU 固有の convolution アルゴリズムを使用できます。

        // simd_any() を使用して、`simdResult` ベクトルのいずれかの要素が `simdThreshold` ベクトルの対応する要素よりも小さいかどうかを確認します。
        DispatchQueue.concurrentPerform(iterations: outputLength) { i in
            // 不要な計算を回避する
            var simdResult = float4x4(
                float4(0.0, 0.0, 0.0, 0.0),
                float4(0.0, 0.0, 0.0, 0.0),
                float4(0.0, 0.0, 0.0, 0.0),
                float4(0.0, 0.0, 0.0, 0.0)
            )

            for j in 0..<m {
                if i - j >= 0 && i - j < n {
                    let signal1Value = float4(Float(signal1[j]))
                    let signal2Value = float4(Float(signal2[i - j]))
                    simdResult = float4x4(simd_add(simdResult, float4x4(diagonal: signal1Value * signal2Value)))
                }
            }

            concurrentQueue.async(flags: .barrier) {
                result[i] = CGFloat(simdResult[0].x + simdResult[0].y + simdResult[0].z + simdResult[0].w +
                                  simdResult[1].x + simdResult[1].y + simdResult[1].z + simdResult[1].w +
                                  simdResult[2].x + simdResult[2].y + simdResult[2].z + simdResult[2].w +
                                  simdResult[3].x + simdResult[3].y + simdResult[3].z + simdResult[3].w)
            }
        }

        return result
    }

<!-- overlap Add + FFT -->
    func convolution(_ signal1: [CGFloat], _ signal2: [CGFloat], blockSize: Int) -> [CGFloat] {
        let m = signal1.count
        let n = signal2.count
        let outputLength = m + n - 1
        
        var result = [CGFloat](repeating: 0, count: outputLength)
        
        let concurrentQueue = DispatchQueue(label: "convolutionQueue", attributes: .concurrent)
        
        DispatchQueue.concurrentPerform(iterations: outputLength) { i in
            for j in stride(from: 0, to: m, by: blockSize) {
                if i - j >= 0 && i - j < n {
                    let blockEnd = min(j + blockSize, m)
                    var block1 = Array(signal1[j..<blockEnd])
                    let block2Start = i - j
                    let block2End = min(block2Start + blockSize, n)
                    var block2 = Array(signal2[block2Start..<block2End])
                    
                    // Zero-padding
                    block1 += Array(repeating: 0, count: blockSize - block1.count)
                    block2 += Array(repeating: 0, count: blockSize - block2.count)
                    
                    // Apply FFT
                    var fftBlock1 = fft(block1)
                    let fftBlock2 = fft(block2)
                    
                    // Multiply in frequency domain (i.e., convolution in time domain)
                    for k in 0..<blockSize {
                        fftBlock1[k] *= fftBlock2[k]
                    }
                    
                    // Apply IFFT and add to the result
                    let ifftBlock = ifft(fftBlock1)
                    concurrentQueue.async(flags: .barrier) {
                        for k in 0..<blockSize {
                            if i + k < result.count {
                                result[i + k] += ifftBlock[k]
                            }
                        }
                    }
                }
            }
        }
        
        return result
    }
